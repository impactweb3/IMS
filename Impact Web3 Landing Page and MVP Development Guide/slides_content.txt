I: Actual number of jobs created (direct and indirect):
Q: How many jobs have been created through your project? Provide details on job type (e.g., full-time, part-time, freelance) and sustainability.
A: Direct jobs: ____
	Indirect jobs: ____
	Optional text field for further explanation.

--------------------------------------------------

Slide 30:
- DATA COLLECTION MODULE - REPORTING FORM
- ENVIRONMENTAL IMPACTS

I: Measured reduction in carbon footprint
Q: What is the measured reduction in carbon footprint achieved during your project’s implementation? Provide data in terms of percentage or specific metrics. 
A: (Open-ended numeric field for specific metrics (e.g., % reduction, tons of CO2 reduced))

I: Adoption rate of renewable energy or other sustainable practices
Q: What percentage of your project’s operations now rely on renewable energy or sustainable practices? Provide adoption rates or qualitative descriptions.
A: Slider/scale for percentage adoption (0–100%)
	Optional text field for describing practices.

I: Actual resource efficiency improvements
Q: What resource efficiency improvements has your project achieved (e.g., waste reduction, energy savings)? Provide specific metrics.
A: Open-ended numeric field (e.g., % waste reduction, energy saved in kWh)

--------------------------------------------------

Slide 31:
- DATA COLLECTION MODULE - REPORTING FORM
- ECONOMIC IMPACTS

I: Realized growth in financial inclusion
Q: How many new wallets or users from your target population have been added as a result of your project? Provide supporting data if possible.
A: Open-ended numeric field

I: Actual revenue generated by the project
Q: What is the total revenue generated by your project? Provide your project’s financial sustainability status (e.g., break-even, profitable).
A: Open-ended numeric field for revenue amount.
	Multiple choice for financial status: Break-even / Profitable / Operating at a loss

I: Economic impact metrics
Q: How many businesses or individuals have benefited economically from your project? Provide details where possible
A: Businesses impacted: ____
	Individuals impacted: ____
	Optional text field for further details.

--------------------------------------------------

Slide 32:
- DATA COLLECTION MODULE - REPORTING FORM
- GOVERNANCE IMPACTS

I: Progress toward governance-related goals
Q: What progress has your project made toward achieving its governance-related goals (e.g., fostering community participation, improving transparency)?
A: Open-ended text for descriptive responses

I: Number of independent partnerships successfully formed
Q: How many independent partnerships have been successfully formed and maintained by your project? Provide details on the nature of these partnerships.
A: Open-ended numeric field for number of partnerships.
	Optional text field for description.

I: Metrics on the effectiveness of governance-related activities
Q: How effective have your governance-related activities been (e.g., voter engagement campaigns)? Provide metrics or examples of success.
A: Open-ended text for qualitative and quantitative responses.

--------------------------------------------------

Slide 33:
- TESTING PLAN FOR IMS PROTOTYPE
- System Performance Testing

Objective: 
Ensure Google Forms can efficiently handle data input and processing for the selected indicators.

Actions:
/ Distribute the Google Form to 15 selected projects (10 finalized from Fund 10/11, 5 ongoing from Fund 12).
/ Test form submission speed and data collection functionality.
/ Track the time required for participants to complete the form.

Metrics:
/ Average time for form completion.
/ Percentage of successful submissions without errors.
/ User feedback on technical issues (if any).

--------------------------------------------------

Slide 34:
- TESTING PLAN FOR IMS PROTOTYPE
- User Interaction Testing

Objective: 
Assess the clarity and ease of answering the questions in the Google Form.

Actions:
/ Include clear instructions for completing the form.
/ Observe a subset of participants completing the form and note any difficulties.
/ Use a follow-up feedback section within the form to gather insights on ease of use and clarity.

Metrics:
/ Average user ratings for form clarity and simplicity (1–5 scale).
/ Number of participants who required assistance.
/ Qualitative feedback on confusing or difficult questions.

--------------------------------------------------

Slide 35:
- TESTING PLAN FOR IMS PROTOTYPE
- Data Output Validation

Objective: 
Ensure the collected data aligns with the defined impact indicators and is usable for analysis.

Actions:
/ Review submitted responses for each indicator.
/ Compare data quality against expected outcomes (e.g., are numeric fields correctly filled, are descriptions clear?).
/ Validate the relevance of responses for impact measurement.

Metrics:
/ Percentage of correctly filled numeric fields (e.g., job creation, financial inclusion numbers).
/ Completeness of qualitative responses.
/ User ratings on the relevance of questions to their project (1–5 scale).

--------------------------------------------------

Slide 36:
- TESTING SCHEDULE FOR IMS PROTOTYPE- FORMS
- /	Create Google Form with all indicator-based questions
/ Share form with 15 selected projects; provide completion guidance.
/ Monitor submissions; track completion times and technical issues.
/ Collect and analyze user feedback on clarity and ease of use.
/ Review responses for accuracy, completeness, and relevance.
/ Summarize findings and recommend refinements for future iterations.

--------------------------------------------------

Slide 37:
- SUCCESS CRITERIA FOR IMS PROTOTYPE
- System performance:
/ The IMS prototype can handle data input and processing efficiently without technical issues.
/ Users can complete data submission forms (via Google Forms) within the expected time and without errors.

User interaction:
/ The system is intuitive, user-friendly, and requires minimal guidance.
/ Participants provide positive feedback on the clarity of questions and ease of navigation.

Data output quality:
/ The data collected is accurate, complete, and aligns with the defined impact indicators.
/ Generated outputs (e.g., impact metrics) are relevant and actionable for stakeholders.

Adoption and feedback:
/ Participants engage actively in the testing process.
/ Recommendations from participants lead to actionable refinements for the MVP.

--------------------------------------------------

Slide 38:
- MILESTONE 2
- Test IMS prototype on 15 projects. Update solution deck with refinements leading to final MVP.

--------------------------------------------------

Slide 39:
- IMS - Project Application Form (Analysis)
- Expected sample - Catalyst fund: 10-5; 11-5; 12-5
47 responses - Catalyst fund: 10-10; 11-17; 12-20 (high-success rate!)

--------------------------------------------------

Slide 40:
- IMS Testing Metrics
- System Performance Testing
/ Average time for form completion - 32.55 minutes (Application form)
The time required to complete the IMS form varies widely, ranging from a few minutes to several hours, depending on the level of detail, project complexity, and preparation, with most respondents estimating an average completion time of 30–60 minutes when information is readily available.
/ Percentage of successful submissions without errors - the overwhelming majority of respondents reported no technical issues
A few respondents noted areas for improvement, such as confusing questions (some questions required clarification or could benefit from clearer instructions), user experience enhancements (suggestions included adding features like saving drafts for later completion, uploading supporting documents, and improving navigation)
/ User feedback on technical issues (if any) - 0 feedback on technical issues

User Interaction Testing
/ Average user ratings for form clarity and simplicity - Clarity - most users found the form reasonably clear, with minor areas for improvement in question clarity and instructions; Simplicity - users generally found the form simple and easy to navigate, with a few recommendations for enhancing user experience further
/ Number of participants who required assistance - 0
/ Qualitative feedback on confusing or difficult questions - some respondents found certain questions, such as those about financial goals or social impact, unclear and suggested improvements like clearer instructions, examples, and rephrasing to reduce ambiguity and enhance user understanding

--------------------------------------------------

Slide 41:
- IMS Testing Metrics
- Data Output Validation
/ Percentage of correctly filled numeric fields (e.g., job creation, financial inclusion numbers) - moderate, as many projects provided estimates but lacked precise or consistent data (improvements in form design (e.g., mandatory numeric inputs) could enhance accuracy)
/ Completeness of qualitative responses - while qualitative responses were generally complete for social and governance-related goals, areas like environmental impact and resource efficiency lacked detail in several cases
/ User ratings on the relevance of questions to their project - questions related to governance and social impact were rated highly relevant by most users, while environmental and financial sustainability sections were less applicable for certain types of projects; tailoring questions based on project categories could improve user experience

--------------------------------------------------

Slide 42:
- IMS - Project Application Form (Analysis)
- Social impacts
 Question: Does your project address any of the following social issues? (Select all that apply, multiple choice)
Response rate: 100% -  55% of projects addressed one social issue; 17% of projects addressed two social issues; 28% of projects addressed three or more social issues
| Educational equity - 48.9% | Poverty reduction - 19.1% | Healthcare access - 8.5% | Broader impact: financial inclusion, environmental benefits        

Lesson learned: 
/ the question effectively captured social impact data, but lacks standardization in responses - more granularity is needed for clearer subcategories
/ predefined response options with checkboxes instead of free-text to ensure more consistent data
/ allow respondents to select multiple subcategories (e.g., Educational equity → Blockchain literacy)
/ separate “Environmental Benefits” explicitly to measure its impact accurately.
/ clarify the definition of “Financial Inclusion” in the question, since some responses mentioned it without selecting it as an explicit category

--------------------------------------------------

Slide 43:
- IMS - Project Application Form (Analysis)
- Social impacts
 Question: Does your project include financial literacy or capacity-building programs? If yes, what outcomes do you expect to achieve?
Yes: 28 responses (59.6%); No: 19 responses (40.4%)
Commonly mentioned outcomes: increased financial inclusion (~40% of responses), skill development and job creation (~35%), improved understanding of blockchain and DeFi (~30%), community empowerment and innovation (~25%):
Average direct jobs created: ~64 jobs per project / Median: 10 jobs per project.
Average indirect jobs created: ~221 jobs per project / Median: 75 jobs per project.

Lesson learned: 
/ the question effectively captured data on social impact 
/ encourage respondents to provide specific metrics or examples for outcomes like “job creation” or “financial inclusion”
/ for projects that do not include financial literacy programs, ask how they indirectly contribute to capacity building or economic growth
/ filter out extreme outliers in job creation estimates to avoid misleading average values; highlight success stories

--------------------------------------------------

Slide 44:
- IMS - Project Application Form (Analysis)
- Environmental impacts
 Question: Does your project address environmental challenges such as clean energy adoption or resource efficiency? If yes, please describe your goals.
Yes: 12 projects (25.5%); No: 35 projects (74.5%)
Common themes among “Yes” responses:
Clean energy adoption: encouraging SPOs to use renewable energy sources, exploring solar-powered blockchain nodes, developing blockchain-based carbon credit tracking
Resource efficiency: optimizing blockchain operations to reduce energy use, enhancing supply chain transparency for sustainability, encouraging green hosting services for Cardano infrastructure

Lesson learned: 
/ the question did not effectively captured data on environmental impact (the question successfully identified projects with direct environmental goals, but many potential contributors were excluded due to the wording)
/ provide guidance or incentives for projects that are not currently addressing environmental challenges to explore indirect contributions (e.g., using energy-efficient hosting, minimizing energy waste)
/ encourage respondents to quantify their expected outcomes (e.g., % reduction in carbon emissions, number of trees planted) for better tracking and evaluation
/ ensure the question differentiates between direct environmental efforts and indirect contributions through blockchain’s energy efficiency

--------------------------------------------------

Slide 45:
- IMS - Project Application Form (Analysis)
- Environmental impacts
 Question: If your project involves reducing carbon footprint or energy consumption, please estimate the expected impact. (e.g., % reduction or specific data)
/ 5 projects provided specific estimates of expected carbon footprint or energy consumption reductions
/ 7 projects discussed energy efficiency without quantifying impacts
/ the remaining projects either skipped the question or stated it was not applicable
/ many projects failed to provide specific estimates due to lack of data collection or unclear expectations

Examples of notable responses:
/ MLabs – SPO-anywhere: estimated a 10–30% reduction in resource consumption per stake pool through NixOS optimization and lightweight configurations
/ Minswap SDK: highlighted Cardano’s PoS mechanism, estimating an 80–90% reduction in carbon emissions compared to PoW blockchains

Lesson learned: 
/ the question did not effectively capture data on environmental impact 
/ projects aiming to reduce carbon footprints must prioritize accurate data collection, stakeholder engagement, and integration of sustainability goals from the outset; encourage projects to report estimated reductions with specific metrics (e.g., kWh saved, % emissions reduction)

--------------------------------------------------

Slide 46:
- IMS - Project Application Form (Analysis)
- Environmental impacts
 Question: Does your project plan to adopt renewable energy or sustainability initiatives? If yes, briefly describe your plans.
Yes: 10 projects (21.3%) / No: 37 projects (78.7%) 
Themes among “Yes” responses: Green hosting & infrastructure optimization (encouraging SPOs to use renewable energy-powered hosting, providing best practices for energy-efficient blockchain infrastructure), renewable energy adoption (a few projects mentioned plans to integrate solar energy or other renewable energy sources, one project discussed using cloud services powered by renewable energy), carbon sequestration & environmental conservation (one project estimated CO2 sequestration from reforestation efforts, another mentioned stakeholder engagement in renewable energy adoption, such as promoting environmentally responsible events)

Lesson learned: 
/ the question did not effectively capture data on environmental impact
/ including quantifiable goals (e.g., % of renewable energy use, estimated CO2 reduction) enhances accountability and allows for better impact assessment
/ some projects could have integrated sustainability components but did not consider them, suggesting a need for more awareness
/ the question should differentiate betwe
(Content truncated due to size limit. Use line ranges to read in chunks)